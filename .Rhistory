TRUEFALSE = interaction(pre_scheme) %in% interaction(corners))
cbind.data.frame(pre_scheme,
TRUEFALSE = interaction(pre_scheme) %in% interaction(corners)) %>%
filter(isFALSE(TRUEFALSE))
pre_scheme %>%
bind_cols(interaction(pre_scheme) %in% interaction(corners)) %>%
filter(isFALSE(TRUEFALSE))
pre_scheme %>%
bind_cols(interaction(pre_scheme) %in% interaction(corners))
jc_scheme <- pre_scheme %>%
bind_cols(interaction(pre_scheme) %in% interaction(corners)) %>%
rename("TF" = 3)
jc_scheme
pre_scheme %>%
cbind.data.frame(interaction(pre_scheme) %in% interaction(corners)) %>%
rename("TF" = 3)
pre_scheme %>%
cbind.data.frame(interaction(pre_scheme) %in% interaction(corners)) %>%
rename("TF" = 3) %>%
filter(isFALSE(TF))
pre_scheme %>%
cbind.data.frame(interaction(pre_scheme) %in% interaction(corners)) %>%
rename("TF" = 3)
pre_scheme %>%
cbind.data.frame(interaction(pre_scheme) %in% interaction(corners)) %>%
rename("TF" = 3) %>%
filter(TF == FALSE)
pre_scheme %>%
cbind.data.frame(interaction(pre_scheme) %in% interaction(corners)) %>%
rename("TF" = 3)
pre_scheme %>%
cbind.data.frame(interaction(pre_scheme) %in% interaction(corners)) %>%
rename("TF" = 3) %>%
as_tibble()
pre_scheme %>%
cbind.data.frame(interaction(pre_scheme) %in% interaction(corners)) %>%
rename("TF" = 3) %>%
as_tibble() %>%
dplyr::filter(TF == F)
pre_scheme %>%
cbind.data.frame(interaction(pre_scheme) %in% interaction(corners)) %>%
rename("TF" = 3) %>%
as_tibble() %>%
dplyr::filter(isFALSE(TF))
pre_scheme %>%
cbind.data.frame(interaction(pre_scheme) %in% interaction(corners)) %>%
rename("TF" = 3) %>%
as_tibble() %>%
dplyr::filter(isFALSE(TF))
pre_scheme %>%
cbind.data.frame(interaction(pre_scheme) %in% interaction(corners)) %>%
rename("TF" = 3) %>%
as_tibble() %>%
dplyr::filter(TF == F)
jc_scheme <- pre_scheme %>%
cbind.data.frame(interaction(pre_scheme) %in% interaction(corners)) %>%
rename("TF" = 3) %>%
as_tibble() %>%
dplyr::filter(TF == F) %>%
select(-TF) %>%
cbind.data.frame(c("P6","P10","P14",
"P2","P5","P9","P13","P16",
"P1","P4","P8","P12","P15",
"P3","P7","P11")) %>%
setNames(c("y","x","label")) %>%
relocate(x,.before = y)
jc_scheme
devtools::check()
roxygen2::roxygenise()
roxygen2::roxygenise()
roxygen2::roxygenise()
roxygen2::roxygenise()
roxygen2::roxygenise()
roxygen2::roxygenise()
roxygen2::roxygenise()
devtools::check()
devtools::check()
roxygen2::roxygenise()
devtools::check()
devtools::check()
x
inherits(-4,"SpatRaster")
is(4, "SpatRaster")
roxygen2::roxygenise()
devtools::check()
roxygen2::roxygenise()
devtools::check()
data(msl)
msl
xmin = -180
xmax = 180
ymin = -80
ymax = 80
U = T
thr = c(6,6)
cores = 1
lons = seq(xmin,xmax,2.5)
lats = seq(ymin,ymax,2.5)
grid <- expand.grid(lons, lats) %>%
filter(.data$Var1 !=-180)
# get lamb points to all grid
points <- apply(grid,
MARGIN = 1,
function(x) get_lamb_points_helper(x[1], x[2]))
points
spatial_lamb(msl, xmin = 5,xmax = 15, ymin = 40, ymax = 50, cores = 1)
msl
xmin = 5
xmax = 15
ymin = 40
ymax = 50
cores = 1
lons = seq(xmin,xmax,2.5)
lats = seq(ymin,ymax,2.5)
grid <- expand.grid(lons, lats) %>%
filter(.data$Var1 !=-180)
# get lamb points to all grid
points <- apply(grid,
MARGIN = 1,
function(x) get_lamb_points_helper(x[1], x[2]))
points
lat_max_required <- max(sapply(points, function(x) max(x[[1]])))
lat_min_required <- min(sapply(points, function(x) min(x[[1]])))
lon_max_required <- max(sapply(points, function(x) max(x[[2]])))
lon_min_required <- min(sapply(points, function(x) min(x[[2]])))
lat_max_required
lat_min_required
lon_max_required
lon_min_required
summary(msl)
cbind.data.frame(pre_scheme,
TF = interaction(pre_scheme) %in% interaction(corners)) %>%
filter(.data$TF == F) %>%
select(-.data$TF) %>%
cbind.data.frame(c("P6","P10","P14",
"P2","P5","P9","P13","P16",
"P1","P4","P8","P12","P15",
"P3","P7","P11"))
roxygen2::roxygenise()
devtools::check()
roxygen2::roxygenise()
devtools::check()
roxygen2::roxygenise()
roxygen2::roxygenise()
devtools::check()
msl
roxygen2::roxygenise()
devtools::check()
roxygen2::roxygenise()
devtools::check()
devtools::build()
devtools::check_built()
devtools::check_built("C:/Users/gc/Desktop/synoptReg_1.2.1.tar.gz")
roxygen2::roxygenise()
devtools::build()
roxygen2::roxygenise()
devtools::build()
roxygen2::roxygenise()
roxygen2::roxygenise()
devtools::build()
roxygen2::roxygenise()
devtools::check()
roxygen2::roxygenise()
devtools::check()
msl
msl <- dplyr::filter(msl, time >= 2000-01-01, time <= 2000-03-30)
msl
roxygen2::roxygenise()
devtools::check()
library(lubridate)
library(dplyr)
data(msl)
msl <- filter(msl, time >= as_date(2000-01-01), time <= as_date(2000-03-30))
msl
msl <- filter(msl, time >= "2000-01-01", time <= "2000-03-30")
msl
library(lubridate)
library(dplyr)
data(msl)
msl <- filter(msl, time >= "2000-01-01", time <= "2000-03-30")
msl
tail(msl)
roxygen2::roxygenise()
devtools::check()
devtools::build()
remove.packages("synoptReg")
remotes::install_github("lemuscanovas/synoptReg")
library(synoptReg)
remove.packages("synoptReg")
devtools::check()
devtools::build()
remotes::install_github("giuliogenova/meteobrowser")
library(MeteoBrowser)
install.packages("spdplyr")
remotes::install_github("mdsumner/spdplyr")
remotes::install_github("giuliogenova/meteobrowser")
devtools::install_git("https://gitlab.inf.unibz.it/earth_observation_public//MonalisR")
remotes::install_github("giuliogenova/meteobrowser")
library(MeteoBrowser)
MeteoBrowser::get_provBz_data
?get_provBz_data
tot_tab_def
MeteoBrowser::legend_tab_def
MeteoBrowser::sspat_def
MeteoBrowser::sspat_def %>% plot
MeteoBrowser::se_spread_def
tot_tab_def
tot_tab_def
unique(tot_tab_def$DESC_E)
filter(tot_tab_def, DESC_E == "Snow height - cm")
remotes::install_github("lemuscanovas/synoptReg")
library(synoptReg)
roxygen2::roxygenise()
devtools::build()
roxygen2::roxygenise()
devtools::build()
remove.packages("synoptReg")
remotes::install_github("lemuscanovas/synoptReg")
library(synoptReg)
roxygen2::roxygenise()
devtools::check()
roxygen2::roxygenise()
devtools::check()
devtools::build()
remove.packages("synoptReg")
d <- as_date(c("2020-01-01","2020-01-01","2020-02-03","2020-05-01"))
library(lubridate)
d
d <- as_date(c("2020-01-01","2020-01-01","2020-02-03","2020-05-01"))
d
rle
rle(d)
rleid(d)
rle(x = d)
d
rle(c(1,1,1,1,2))
d %>% group_by(d)
library(tidyverse)
d %>% group_by(d)
d
d == lag(d)
d-lag
lag(d) == d
lag(d,n = 1) == d
d == lag(d)
isTrue(d == lag(d))
isTRUE(d == lag(d))
any(d == lag(d)) == T
any(d == lag(d)) == F
read_nc <- function(x, anomaly = F, time_subset = NULL, month_subset = NULL,
crop_area = NULL, aggregate = NULL){
if(is(x, "SpatRaster")){
dat <- x
} else {
dat <- rast(x)
}
varname <- varnames(dat) %>% unique
unit <- units(dat) %>% unique
dates <- terra::time(dat)
if((!is.Date(dates) | !is.POSIXct(dates)) == T){
stop("Not readable time string or not provided!")
}
dates_daily <- as_date(dates)
if(any(d == lag(d)) == T){
dat <- tapp(dat,as.factor(dates_daily),"mean")
}
terra::time(dat) <- unique(dates_daily)
if(isTRUE(anomaly)){
mean <- app(dat, "mean")
dat <- dat - mean
}
varnames(dat) <- varname
units(dat) <- unit
if(!is.null(time_subset)){
dates <- terra::time(var)
class(dates)
if(is(dates, "Date")){
sel <- which(dates %in% as_date(time_subset))
dat <- dat[[sel]]}
else{
stop("Data provided must be daily-based. Try use daily_mean = T")
}
}
if(!is.null(month_subset)){
dates <- terra::time(dat)
class(dates)
if(is(dates, "Date")){
sel <- which(month(dates) %in% month_subset)
dat <- dat[[sel]]
}else{
stop("Data provided must be daily-based. Try use daily_mean = T")
}
}
if(!is.null(crop_area)){
dat <- crop(dat, crop_area)
}
if(!is.null(aggregate)){
dat <- terra::aggregate(dat, 2)
}
return(dat)
}
read_nc(pcp)
dates
((!is.Date(dates) | !is.POSIXct(dates)) == T)
dates
class(dates)
is.Date(dates)
dates
dates
read_nc <- function(x, anomaly = F, time_subset = NULL, month_subset = NULL,
crop_area = NULL, aggregate = NULL){
if(is(x, "SpatRaster")){
dat <- x
} else {
dat <- rast(x)
}
varname <- varnames(dat) %>% unique
unit <- units(dat) %>% unique
dates <- terra::time(dat)
if(sum(inherits(dates, "Date") + inherits(dates, "POSIXct") == 0)){
stop("Not readable time string or not provided!")
}
dates_daily <- as_date(dates)
if(any(d == lag(d)) == T){
dat <- tapp(dat,as.factor(dates_daily),"mean")
}
terra::time(dat) <- unique(dates_daily)
if(isTRUE(anomaly)){
mean <- app(dat, "mean")
dat <- dat - mean
}
varnames(dat) <- varname
units(dat) <- unit
if(!is.null(time_subset)){
dates <- terra::time(var)
class(dates)
if(is(dates, "Date")){
sel <- which(dates %in% as_date(time_subset))
dat <- dat[[sel]]}
else{
stop("Data provided must be daily-based. Try use daily_mean = T")
}
}
if(!is.null(month_subset)){
dates <- terra::time(dat)
class(dates)
if(is(dates, "Date")){
sel <- which(month(dates) %in% month_subset)
dat <- dat[[sel]]
}else{
stop("Data provided must be daily-based. Try use daily_mean = T")
}
}
if(!is.null(crop_area)){
dat <- crop(dat, crop_area)
}
if(!is.null(aggregate)){
dat <- terra::aggregate(dat, 2)
}
return(dat)
}
read_nc <- function(x, anomaly = F, time_subset = NULL, month_subset = NULL,
crop_area = NULL, aggregate = NULL){
if(is(x, "SpatRaster")){
dat <- x
} else {
dat <- rast(x)
}
varname <- varnames(dat) %>% unique
unit <- units(dat) %>% unique
dates <- terra::time(dat)
if(sum(inherits(dates, "Date") + inherits(dates, "POSIXct") == 0)){
stop("Not readable time string or not provided!")
}
dates_daily <- as_date(dates)
if(any(dates_daily == lag(dates_daily),na.rm = T) == T){
dat <- tapp(dat,as.factor(dates_daily),"mean")
}
terra::time(dat) <- unique(dates_daily)
if(isTRUE(anomaly)){
mean <- app(dat, "mean")
dat <- dat - mean
}
varnames(dat) <- varname
units(dat) <- unit
if(!is.null(time_subset)){
dates <- terra::time(var)
class(dates)
if(is(dates, "Date")){
sel <- which(dates %in% as_date(time_subset))
dat <- dat[[sel]]}
else{
stop("Data provided must be daily-based. Try use daily_mean = T")
}
}
if(!is.null(month_subset)){
dates <- terra::time(dat)
class(dates)
if(is(dates, "Date")){
sel <- which(month(dates) %in% month_subset)
dat <- dat[[sel]]
}else{
stop("Data provided must be daily-based. Try use daily_mean = T")
}
}
if(!is.null(crop_area)){
dat <- crop(dat, crop_area)
}
if(!is.null(aggregate)){
dat <- terra::aggregate(dat, 2)
}
return(dat)
}
clas
dates_env <- time(x)
dates_clas <- clas$time
roxygen2::roxygenise()
roxygen2::roxygenise()
library(devtools)
devtools::check()
devtools::check()
devtools::build()
checkCRAN()
devtools::check_win_release()
library(synoptReg)
?read_nc
# Load data (mslp or precp_grid)
slp_file <- system.file("extdata", "mslp_ei.nc", package = "synoptReg")
# Reading data simply
slp <- read_nc(slp_file)
slp
# Adapting the slp data structure to the synoptReg needs
slp <- as_synoptReg(slp)
slp
z500_file <- system.file("extdata", "z500_ei.nc", package = "synoptReg")
msl_file <- system.file("extdata", "mslp_ei.nc", package = "synoptReg")
read_nc(z500_file)
# Load data (mslp or precp_grid)
z500_file <- system.file("extdata", "z500_ei.nc", package = "synoptReg")
# Reading data simply
z500 <- read_nc(z500_file)
# Adapting the slp data structure to the synoptReg needs
z500 <- as_synoptReg(z500)
# Scree test
info <- pca_decision(z500,ncomp = 30,norm = T,matrix_mode = "T-mode")
# Load precipitation data and filtering torrential days
pcp_file <- system.file("extdata", "pcp_spread.nc", package = "synoptReg")
pcp <- read_nc(pcp_file) %>% as_synoptReg()
torrential_dates <- pcp %>%
filter(value >= 100) %>%
distinct(time) %>%
pull()
torrential_dates <- pcp %>%
filter(value >= 100) %>%
distinct(time) %>%
as.vector()
library(tidyverse)
torrential_dates <- pcp %>%
filter(value >= 100) %>%
distinct(time) %>%
pull()
# Load data (mslp or precp_grid)
z500_file <- system.file("extdata", "z500_ei.nc", package = "synoptReg")
# Reading data simply
z500 <- read_nc(z500_file)
# Adapting the slp data structure to the synoptReg needs
z500 <- as_synoptReg(z500)
# Scree test
info <- pca_decision(z500,ncomp = 30,norm = T,matrix_mode = "T-mode")
# Adapting the slp data structure to the synoptReg needs
z500 <- as_synoptReg(z500) %>%
filter(time %in% torrential_dates) # Here we filter the z500 with just torrential dates
as_synoptReg(z500)
# Reading data simply
z500 <- read_nc(z500_file)
# Adapting the slp data structure to the synoptReg needs
z500 <- as_synoptReg(z500) %>%
filter(time %in% torrential_dates) # Here we filter the z500 with just torrential dates
z500
# Scree test
info <- pca_decision(z500,ncomp = 30,norm = T,matrix_mode = "T-mode")
# Scree test for a T-mode
info <- pca_decision(z500,ncomp = 30,norm = T,matrix_mode = "T-mode")
info$screeplot
# Classification with 6 PCs
cl <- synoptclas(vars_torrential,ncomp = 6,norm = T,matrix_mode = "T-mode")
# Classification with 6 PCs
cl <- synoptclas(z500,ncomp = 6,norm = T,matrix_mode = "T-mode")
cl$clas_max
######
#In case you need to download data, you can use download_ncep()
# Example
z500_ncep <- download_ncep(var = "hgt",
level = 500,
month_range = c(6:8),
year_range = c(1990,1991),
lat_range = c(30,60),
lon_range = c(-10,20),
dailymean = T,
save_download = T,
file_name = "z500_test.nc"
)
z500_ncep
z500
pca_decision(z500_ncep,ncomp = 30,norm = T,matrix_mode = "T-mode")
# Data downloaded needs to be formatted as the download_ncep function needs
# to be upgraded
z500_ncep <- z500_ncep %>%
mutate(var = "hgt",
units = "m")
pca_decision(z500_ncep,ncomp = 30,norm = T,matrix_mode = "T-mode")
pca_decision(z500_ncep,ncomp = 30,norm = T,matrix_mode = "S-mode")
